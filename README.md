# üî¢ Handwritten Digit Recognition System

An advanced deep learning solution for handwritten digit recognition using **PyTorch**, featuring a robust **CNN architecture**, **data augmentation**, **regularization**, and strong **evaluation metrics**. This project includes both a standard **MNIST pipeline** and a **Kaggle competition-ready workflow**.

---

## üìã Table of Contents

1. [About the Dataset](#about-the-dataset)  
2. [Project Structure](#project-structure)  
3. [Model Architecture](#model-architecture)  
4. [Key Features](#key-features)  
5. [Training Pipeline Overview](#training-pipeline-overview)  
6. [Requirements](#requirements)  
7. [Usage](#usage)  
8. [Results](#results)  
9. [License](#license)
10. [Contributing](#contributing)

---

## üìä About the Dataset

This system is built on the **MNIST Dataset**:

- **60,000** grayscale images for training (28√ó28 pixels)  
- **10,000** images for testing  
- **10 classes** labeled **0‚Äì9**  
- Images are **pre-centered**, **normalized**, and **automatically downloaded** via `torchvision`  
- Includes optional **Kaggle support** with submission formatting  

---

## üóÇ Project Structure
```
Digit-Recognition/
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ LICENSE
‚îú‚îÄ‚îÄ README.md                   # Project documentation (this file)
‚îú‚îÄ‚îÄ digit_recognizer.ipynb      # Full MNIST pipeline in PyTorch
‚îú‚îÄ‚îÄ transfer_learning/
‚îÇ   ‚îú‚îÄ‚îÄ digit_recognizer_resnet50.ipynb  # Advanced transfer learning with ResNet50
‚îÇ   ‚îî‚îÄ‚îÄ README.md               # Transfer learning documentation
‚îî‚îÄ‚îÄ Kaggle Competition/
    ‚îú‚îÄ‚îÄ submissions.csv         # Prediction submission file for Kaggle
    ‚îî‚îÄ‚îÄ digit_recognizer_kaggle.ipynb # Kaggle-compatible training & inference notebook
```
---

## üß† Model Architecture
```
Input Image (28x28x1)
        ‚Üì
3√ó [Conv2D + BatchNorm + ReLU]
   ‚Ü≥ MaxPool2D, Dropout after each stage
        ‚Üì
AdaptiveAvgPool2d (Global)
        ‚Üì
Flatten ‚Üí FC Layer (512) ‚Üí BatchNorm ‚Üí ReLU ‚Üí Dropout
        ‚Üì
Output Layer (10 classes - digits 0‚Äì9)
```
---

## üß† Model Overview

- **Convolutional Backbone**: Multi-stage feature extraction with 3 convolutional blocks  
- **Classifier Head**: Adaptive pooling, flattening, and regularized fully connected layers  
- **Final Output**: 10 logits, one for each digit class  

---

## ‚ú® Key Features

- **Data Augmentation**: Random rotation & translation, enhancing resilience to handwriting variability  
- **Batch Normalization & Dropout**: Applied in both convolutional and dense layers for stable, regularized training  
- **Label Smoothing**: Reduces overconfidence, improving model calibration  
- **Early Stopping**: Prevents overfitting by monitoring validation loss  
- **Learning Rate Scheduler**: Stepwise adjustments for refined convergence  
- **Visualization**: Sample images, loss curves, and detailed prediction grids  

---

## üîÅ Training Pipeline Overview

### 1. üìÇ Data Preparation
- Downloads and decompresses **MNIST** via `torchvision` (auto-download)  
- Applies **augmentation** (random rotation, translation, normalization)  
- Splits data into **training (80%)** and **validation (20%)** sets  
- `DataLoaders` manage loading for all splits efficiently  

### 2. ‚öôÔ∏è Model Setup
- Defines a **CNN** with 3 convolutional blocks, **batch normalization**, and **dropout**  
- Uses **adaptive average pooling** for resilience to input size changes  

### 3. üèãÔ∏è Training
- **Adam optimizer** with **cross-entropy loss** (label smoothing enabled)  
- Best weights saved based on **lowest validation loss**  
- **Early stopping** to avoid overfitting  
- **Learning rate** is reduced at milestones for fine-tuning  

### 4. üß™ Evaluation
- Reloads **best model** for testing  
- **Per-class** and **overall accuracy** computed on the test set  
- Visualizes predictions with **correct/incorrect highlights**  

---

## ‚öôÔ∏è Requirements
```
python>=3.8
torch>=1.9
torchvision
numpy
matplotlib
seaborn
pandas
```

These requirements can be easily installed by: pip install -r requirements.txt

---

## üöÄ Usage

### 1. Run Standard Training
- Open `digit_recognizer.ipynb` in **Jupyter** or compatible editors.
  ```
  cnn_model = CNN()
  cnn_model.to(device)
  cnn_loss = trainCNN(cnn_model)
  ```
- The best weights are automatically saved as `CNN_model.pth`.

### 2. Visualize Training Progress
- Loss and accuracy curves, prediction grids, and confusion matrices can be visualized interactively in the notebook.
  ```
  plt.plot(cnn_loss['train'], label='Training Loss')
  plt.plot(cnn_loss['valid'], label='Validation Loss')
  plt.legend()
  plt.show()
  ```

### 3. Testing & Evaluation
- Evaluation on the test set is performed with detailed accuracy metrics and visual diagnostics.
  ```
  cnn_model.load_state_dict(torch.load('CNN_model.pth', map_location=device))
  testCNN(cnn_model)
  ```  

### 4. Kaggle Submission
- Navigate to `Kaggle Competition/digit_recognizer_kaggle.ipynb`, run all cells, and generate `submissions.csv` for Kaggle upload.

---

## üìà Results

- **Test Accuracy**: Consistently exceeds **99%** on MNIST  
- **Per-Class Accuracy**: High accuracy across all digits due to effective augmentation and regularization  
- **Visualization**: Intuitive grids clearly distinguish correct (**green**) and incorrect (**red**) predictions  

---

## üìÑ License

This project is licensed under the **MIT License**.  
See the [LICENSE](LICENSE) file for details.

---

## ü§ù Contributing

### üí° Opportunities for Contribution:

- **Ensemble Approaches**: Blend predictions from multiple models for increased robustness  
- **Adversarial Testing**: Explore model resilience against perturbed samples  
- **Explainability**: Integrate feature visualization tools   
- **Advanced Augmentation**: Implement methods like **elastic distortions**, **cutout**, or **mixup**

### üîß How to Contribute:

1. Fork the repository  
2. Create a feature branch  
   ```bash
   git checkout -b feature/new-feature
3.	Make your changes with appropriate documentation and tests
4.	Submit a pull request with a clear and concise description

---

‚≠ê If this project helps you, consider giving it a star!

